# Defaults for eval.py.
#
#
# You must also include a binding for MODEL.
#
# Required to be set:
#
# - CHECKPOINT_PATH: The model checkpoint to evaluate
# - EVAL_OUTPUT_DIR: The dir to write results to.
#
#
# Commonly overridden options:
#
# - DatasetConfig.split
# - DatasetConfig.batch_size
from __gin__ import dynamic_registration

import __main__ as eval_script
from t5x import partitioning
from t5x import utils

import seqio
from seqio import loggers
from hyper_task_descriptions.seqio_tasks import all_t0_tasks # Needed to define the t0 eval mixtures

# Must be overridden
MIXTURE_OR_TASK_NAME = "t0_eval_score_eval"
CHECKPOINT_PATH = %gin.REQUIRED
EVAL_OUTPUT_DIR = %gin.REQUIRED
TASK_FEATURE_LENGTHS = {"inputs": 1024, "targets": 256}
DROPOUT_RATE = 0.0

# DEPRECATED: Import the this module in your gin file.
MIXTURE_OR_TASK_MODULE = None

eval_script.evaluate:
  model = %MODEL  # imported from separate gin file
  dataset_cfg = @utils.DatasetConfig()
  partitioner = @partitioning.PjitPartitioner()
  restore_checkpoint_cfg = @utils.RestoreCheckpointConfig()
  output_dir = %EVAL_OUTPUT_DIR
  inference_evaluator_cls = @seqio.Evaluator

seqio.Evaluator.logger_cls = [@loggers.JSONLogger, @seqio.TensorBoardLogger]

partitioning.PjitPartitioner.num_partitions = 2

utils.DatasetConfig:
  mixture_or_task_name = %MIXTURE_OR_TASK_NAME
  task_feature_lengths = %TASK_FEATURE_LENGTHS
  split = 'validation'
  batch_size = 256
  shuffle = False
  seed = None
  use_cached = True
  pack = False
  use_custom_packing_ops = False
  module = %MIXTURE_OR_TASK_MODULE

utils.RestoreCheckpointConfig:
  path = %CHECKPOINT_PATH
  mode = 'specific'
  dtype = 'float32'