# T5.1.1 XL model.

include 'gins/lora/plain/lora_base.gin'  # imports vocab, optimizer and model.

# ------------------- Network specification overrides --------------------------
lora_network.LoraTransformer.config = @hyper_network.HyperT5Config()
hyper_network.HyperT5Config:
  emb_dim = 2048
  num_heads = 32
  num_encoder_layers = 24
  num_decoder_layers = 24
  head_dim = 64
  mlp_dim = 5120
  lora_ranks = (8, None, 8, None)
